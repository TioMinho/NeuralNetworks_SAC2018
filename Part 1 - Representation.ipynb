{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - A Practical Introduction\n",
    "by _Minho Menezes_  \n",
    "\n",
    "---\n",
    "\n",
    "## Neural Networks - Representation\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LIBRARIES ##\n",
    "import numpy as np                         # Library for Numerical and Matricial Operations\n",
    "import matplotlib.pyplot as plt            # Library for Generating Visualizations\n",
    "from mpl_toolkits.mplot3d import Axes3D    # Library for Generating 3D Visualizations\n",
    "import pandas as pd                        # Library for Handling Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CLASS: Multilayer Perceptron ##\n",
    "class MultilayerPerceptron(object):\n",
    "    \n",
    "    # CLASS CONSTRUCTOR\n",
    "    def __init__(self, n_neurons=[2, 5, 1]):\n",
    "        if(len(n_neurons) < 2):\n",
    "            raise ValueError(\"The network must have at least two layers! (The input and the output layers)\")\n",
    "        \n",
    "        # Network Architecture\n",
    "        self.hidden_layers = len(n_neurons)-2\n",
    "        self.n_neurons = n_neurons\n",
    "        self.W = []\n",
    "        \n",
    "        # Adjusting the Network architecture\n",
    "        for i in range(1, len(n_neurons)):\n",
    "            self.W.append( np.random.randn(self.n_neurons[i-1]+1 , self.n_neurons[i]) )\n",
    "        \n",
    "    # ACTIVATION FUNCTION\n",
    "    def activate(self,Z):\n",
    "        pass\n",
    "    \n",
    "    # FORWARD PROPAGATION\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "        \n",
    "## ---------------------------- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Layer Perceptron\n",
    "\n",
    "The **Single-Layer Perceptron**, also known by the alias of Logistic Units, are the fundamental component of most of the connected Neural Networks that we study, so they are refered as to the _neurons_ of such Networks. This is a graphic representation of a Single-Layer Perceptron:\n",
    "\n",
    "[img]\n",
    "\n",
    "Write the code for the activation of such neuron in below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activate(self, Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def forward(self, X):\n",
    "    X = np.vstack([np.ones([1, X.shape[1]]), X])\n",
    "    Z = np.matmul(self.W[0].T, X)\n",
    "    A = self.activate(Z)\n",
    "    \n",
    "    return A \n",
    "\n",
    "MultilayerPerceptron.activate = activate\n",
    "MultilayerPerceptron.forward = forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78110308]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1.5],\n",
    "              [ -2]])\n",
    "\n",
    "Y = np.array([[1]])\n",
    "\n",
    "brain = MultilayerPerceptron(n_neurons=[2,1])\n",
    "brain.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = np.linspace(-15, 20, 50)\n",
    "y = np.linspace(-15, 20, 50)\n",
    "\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "data = np.vstack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "z = brain.forward(data)\n",
    "zz = z.reshape(xx.shape)\n",
    "\n",
    "ax.plot_wireframe(xx,yy,zz)\n",
    "ax.scatter3D(X[0,:],X[1,:], Y, c=\"Red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward(self, X):\n",
    "        # Activation List\n",
    "        A = []\n",
    "        \n",
    "        # Input Layer Activation\n",
    "        A.append( np.vstack([np.ones([1, X.shape[1]]), X]) )\n",
    "        \n",
    "        # Hidden Layer Activation\n",
    "        for i in range(0, self.hidden_layers):\n",
    "            Z = np.matmul(self.W[i].T, A[-1])\n",
    "            Z = self.activate(Z)\n",
    "            \n",
    "            A.append( np.vstack([np.ones([1, Z.shape[1]]), Z]) )\n",
    "        \n",
    "        # Output Layer Activation\n",
    "        Z = np.matmul(self.W[-1].T, A[-1])\n",
    "        Z = self.activate(Z)\n",
    "\n",
    "        A.append(Z)\n",
    "        \n",
    "        return A\n",
    "    \n",
    "MultilayerPerceptron.forward = forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  1.],\n",
       "        [ 2.,  8.],\n",
       "        [-2.,  6.]]), array([[  1.00000000e+00,   1.00000000e+00],\n",
       "        [  9.12324371e-01,   7.26732580e-09],\n",
       "        [  3.42755538e-01,   4.95794953e-03],\n",
       "        [  6.37102117e-03,   5.15668121e-05],\n",
       "        [  3.34836160e-01,   9.64893183e-01],\n",
       "        [  9.20597316e-01,   3.38006715e-05]]), array([[ 0.84619223,  0.6601097 ]])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[ 2, 8],\n",
    "              [-2, 6]])\n",
    "\n",
    "Y = np.array([[1, 0]])\n",
    "\n",
    "brain = MultilayerPerceptron(n_neurons=[2,5,1])\n",
    "brain.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = np.linspace(-20, 20, 50)\n",
    "y = np.linspace(-20, 20, 50)\n",
    "\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "data = np.vstack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "z = brain.forward(data)[-1]\n",
    "zz = z.reshape(xx.shape)\n",
    "\n",
    "ax.plot_wireframe(xx,yy,zz)\n",
    "ax.scatter3D(X[0,:],X[1,:], Y, c=\"Red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MULTICLASS\n",
    "X = np.array([[ 2, -8],\n",
    "              [-2, 6]])\n",
    "\n",
    "Y = np.array([[1, 0]])\n",
    "W = [np.random.randn(3,125), np.random.randn(126,10)]\n",
    "\n",
    "a = forward(X, W)[-1]\n",
    "(a == a.max(axis=0, keepdims=True)).astype(int)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
