{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - A Practical Introduction\n",
    "by _Minho Menezes_  \n",
    "\n",
    "---\n",
    "\n",
    "## Multilayer Perceptron for Computer Vision\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIBRARIES ##\n",
    "import numpy as np                         # Library for Numerical and Matricial Operations\n",
    "import matplotlib.pyplot as plt            # Library for Generating Visualizations\n",
    "import pandas as pd                        # Library for Handling Datasets\n",
    "from tools.tools import Tools as tl        # Library for some Utilitary Tools\n",
    "\n",
    "# Function for loading the MNIST dataset into a Numpy Matrix\n",
    "import pickle\n",
    "\n",
    "def loadMNIST():\n",
    "    with open(\"data/mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"].T, mnist[\"test_images\"].T, mnist[\"training_labels\"].T, mnist[\"test_labels\"].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Neural Networks Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASS: Multilayer Perceptron ##\n",
    "class MultilayerPerceptron:\n",
    "    \n",
    "    # CLASS CONSTRUCTOR\n",
    "    def __init__(self, n_neurons=[2, 5, 1]):\n",
    "        if(len(n_neurons) < 2):\n",
    "            raise ValueError(\"The network must have at least two layers! (The input and the output layers)\")\n",
    "        \n",
    "        # Network Architecture\n",
    "        self.hidden_layers = len(n_neurons)-2\n",
    "        self.n_neurons = n_neurons\n",
    "        self.W = []\n",
    "        \n",
    "        # Adjusting the Network architecture\n",
    "        for i in range(1, len(n_neurons)):\n",
    "            self.W.append( np.random.randn(self.n_neurons[i-1]+1 , self.n_neurons[i]) )\n",
    "        \n",
    "    # ACTIVATION FUNCTION\n",
    "    def activate(self,Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    # FORWARD PROPAGATION\n",
    "    def forward(self, X):\n",
    "        # Activation List\n",
    "        A = []\n",
    "        \n",
    "        # Input Layer Activation\n",
    "        A.append( np.vstack([np.ones([1, X.shape[1]]), X]) )\n",
    "        \n",
    "        # Hidden Layer Activation\n",
    "        for i in range(0, self.hidden_layers):\n",
    "            Z = np.matmul(self.W[i].T, A[-1])\n",
    "            Z = self.activate(Z)\n",
    "            \n",
    "            A.append( np.vstack([np.ones([1, Z.shape[1]]), Z]) )\n",
    "        \n",
    "        # Output Layer Activation\n",
    "        Z = np.matmul(self.W[-1].T, A[-1])\n",
    "        Z = self.activate(Z)\n",
    "\n",
    "        A.append(Z)\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    # CLASSIFICATION PREDICTION\n",
    "    def predict(self, X):\n",
    "        A = self.forward(X)\n",
    "        \n",
    "        if(self.n_neurons[-1] > 1):\n",
    "            return A[-1].argmax(axis=0)\n",
    "        else:\n",
    "            return (A[-1] > 0.5).astype(int)\n",
    "    \n",
    "    # LOSS FUNCTION\n",
    "    def loss(self, y, y_hat):\n",
    "        m = y.shape[1]\n",
    "        return -(1/m) * np.sum(y * np.log(y_hat) + (1-y) * np.log(1 - y_hat))\n",
    "    \n",
    "    # ACCURACY FUNCTION\n",
    "    def accuracy(self, y, y_hat):\n",
    "        m = y.shape[1]\n",
    "        return (1/m) * np.sum(y == y_hat) * 100\n",
    "    \n",
    "    # BACKPROPAGATION\n",
    "    def backpropagate(self, A, y):\n",
    "        # A primeira matriz de erros é calculada diretamente da diferença entre a classe real e a prevista\n",
    "        E = []\n",
    "        E.append( A[-1] - y )\n",
    "\n",
    "        # O erro é, então, propagado para trás até termos os erros da primeira Camada oculta\n",
    "        for i in range(self.hidden_layers, 0, -1):\n",
    "            E.append( np.matmul(self.W[i], E[-1]) * A[i] * (1-A[i]) )\n",
    "            E[-1] = E[-1][1:,:]\n",
    "\n",
    "        # Retornamos o erro calculado em todas as camadas, na ordem inversa do cálculo\n",
    "        return E[::-1]\n",
    "    \n",
    "    # GRADIENT DESCENT TRAINING\n",
    "    def train(self, X_train, y_train, alpha=1e-3, maxIt=50000, tol=1e-5, verbose=False):\n",
    "        m = X_train.shape[1]\n",
    "    \n",
    "        # Define o Histórico de Erros e algumas variáveis auxiliares\n",
    "        errorHist = []\n",
    "        previousLoss = 0\n",
    "\n",
    "        # Realiza o treino por Gradiente Descendente\n",
    "        for it in range(0, maxIt):\n",
    "            # 1. Calculamos a ativação de todos os neurônios (Forward Propagation) e \n",
    "            #    retropropagamos o erro da predição (Backpropagation)\n",
    "            A = self.forward(X_train)\n",
    "            E = self.backpropagate(A, y_train)\n",
    "            P = self.predict(X_train)\n",
    "\n",
    "            # 2. Calculamos o erro MSE, a acurácia do modelo e adicionamos o resultado no histórico.\n",
    "            actualLoss = self.loss(y_train, A[-1])\n",
    "            actualAcc = self.accuracy(y_train, P)\n",
    "            errorHist.append(actualLoss)\n",
    "\n",
    "            # 3. Realizamos o passo do Gradiente Descendente.        \n",
    "            for i in range(0, self.hidden_layers+1):\n",
    "                self.W[i] = self.W[i] - (alpha/m) * np.matmul(A[i], E[i].T)\n",
    "\n",
    "            # 4. Imprimimos o resultado do treinamento a cada 50 épocas.\n",
    "            if(it % 50 == 0 and verbose): \n",
    "                print(\"## Iteration\", it, \"##\")\n",
    "                print(\"Cross-Entropy Loss: \\t\", actualLoss)\n",
    "                print(\"Accuracy (Training Set): {0:.3f}%\".format(actualAcc))\n",
    "                print(\"Weights\\nS -> H:\\n\", self.W[0], \"\\nH -> O:\\n\", self.W[1])\n",
    "                print(\"\\n\")\n",
    "\n",
    "            # 5. Verificamos uma possivel convergência do treinamento, e então encerramos o laço.\n",
    "            if(abs(actualLoss - previousLoss) <= tol):\n",
    "                print(\"!!! Convergence reached !!!\")\n",
    "                print(\"## Iteration\", it, \"##\")\n",
    "                print(\"Cross-Entropy Loss: \\t\", actualLoss)\n",
    "                print(\"Accuracy (Training Set): {0:.3f}%\".format(actualAcc))\n",
    "                print(\"Weights\\nS -> H:\\n\", self.W[0], \"\\nH -> O:\\n\", self.W[1])\n",
    "                print(\"\\n\")\n",
    "                break;\n",
    "\n",
    "            # 6. Atualizamos as variáveis auxiliares para as próximas iterações.\n",
    "            previousLoss = actualLoss\n",
    "\n",
    "        # Fim do Treinamento\n",
    "        return errorHist\n",
    "        \n",
    "## ---------------------------- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Image Data Extraction\n",
    "\n",
    "When working with Computer Vision, the first thing you need, of course, is to be able to open image data and format it to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
